{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Requirement already satisfied: unionllm in /opt/homebrew/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.11/site-packages (from unionllm) (1.28.1)\n",
      "Requirement already satisfied: pydantic in /opt/homebrew/lib/python3.11/site-packages (from unionllm) (2.7.1)\n",
      "Requirement already satisfied: zhipuai in /opt/homebrew/lib/python3.11/site-packages (from unionllm) (2.0.1.20240429)\n",
      "Requirement already satisfied: tenacity in /opt/homebrew/lib/python3.11/site-packages (from unionllm) (8.2.3)\n",
      "Requirement already satisfied: dashscope in /opt/homebrew/lib/python3.11/site-packages (from unionllm) (1.11.0)\n",
      "Requirement already satisfied: websocket-client in /opt/homebrew/lib/python3.11/site-packages (from unionllm) (1.8.0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from unionllm) (2.31.0)\n",
      "Requirement already satisfied: pytest in /opt/homebrew/lib/python3.11/site-packages (from unionllm) (8.2.0)\n",
      "Requirement already satisfied: litellm in /opt/homebrew/lib/python3.11/site-packages (from unionllm) (1.37.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.11/site-packages (from dashscope->unionllm) (3.9.3)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.11/site-packages (from litellm->unionllm) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /opt/homebrew/lib/python3.11/site-packages (from litellm->unionllm) (7.0.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /opt/homebrew/lib/python3.11/site-packages (from litellm->unionllm) (3.1.3)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /opt/homebrew/lib/python3.11/site-packages (from litellm->unionllm) (1.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from litellm->unionllm) (0.5.2)\n",
      "Requirement already satisfied: tokenizers in /opt/homebrew/lib/python3.11/site-packages (from litellm->unionllm) (0.13.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/lib/python3.11/site-packages (from openai->unionllm) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.11/site-packages (from openai->unionllm) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from openai->unionllm) (0.25.2)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.11/site-packages (from openai->unionllm) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/lib/python3.11/site-packages (from openai->unionllm) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/homebrew/lib/python3.11/site-packages (from openai->unionllm) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic->unionllm) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /opt/homebrew/lib/python3.11/site-packages (from pydantic->unionllm) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->unionllm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->unionllm) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->unionllm) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->unionllm) (2023.11.17)\n",
      "Requirement already satisfied: iniconfig in /opt/homebrew/lib/python3.11/site-packages (from pytest->unionllm) (2.0.0)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/lib/python3.11/site-packages (from pytest->unionllm) (23.2)\n",
      "Requirement already satisfied: pluggy<2.0,>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from pytest->unionllm) (1.5.0)\n",
      "Requirement already satisfied: cachetools>=4.2.2 in /opt/homebrew/lib/python3.11/site-packages (from zhipuai->unionllm) (5.3.1)\n",
      "Requirement already satisfied: pyjwt<2.9.0,>=2.8.0 in /opt/homebrew/lib/python3.11/site-packages (from zhipuai->unionllm) (2.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->unionllm) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->unionllm) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/homebrew/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm->unionllm) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm->unionllm) (2.1.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/lib/python3.11/site-packages (from tiktoken>=0.4.0->litellm->unionllm) (2023.12.25)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->dashscope->unionllm) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->dashscope->unionllm) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->dashscope->unionllm) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->dashscope->unionllm) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->dashscope->unionllm) (1.9.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install unionllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# install the required packages\n",
    "from unionllm import unionchat\n",
    "from datasets import Dataset\n",
    "from zeval.evaluation import evaluate\n",
    "from zeval.evaluators import Faithfulness, AnswerRelevancy, ContextRecall, ContextPrecision\n",
    "# from evalsone import EvalsOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='3f6d5e8142eb4d5984a88b93b4e007d0', choices=[Choices(finish_reason='stop', index=0, message=Message(content='瑞文标准智力测验是一款广受认可的智力测验工具，它是一种纯粹的非文字智力测验。在这里，你可以进行智力测验：\\n\\n[点击这里进行瑞文标准智力测验](http://p.melbacastillo.top/pquiz/rend/2725039?retake=1\\\\u0026cstr=5c987b7c4001f)\\n\\n请记住，瑞文智力测验结果与测试参与者在测验时的精神状态，周边环境等多种因素有关，波动范围大约在3至15分左右。', role='assistant'))], created=1716650197, model='', object='chat.completion', system_fingerprint=None, usage=Usage(), context=[])\n"
     ]
    }
   ],
   "source": [
    "# query Coze with a query and get the completion and the context\n",
    "query = \"智商测试\"\n",
    "ideal = [\"瑞文标准推理测验（SPM）是一种广受认可的智力测验工具，由英国心理学家瑞文于1938年创制。该测验是一种纯粹的非文字智力测验，广泛应用于无国界的智力/推理能力测试。它基于斯皮尔曼的智力二因素论，认为智力主要由普通因素（G因素）和特殊因素（S因素）构成。瑞文测验主要测量“G”因素，与问题解决、清晰知觉和思维、发现和利用信息以及适应社会生活能力相关。该测验由60张图组成，分为5个单元，考察了知觉辨别、类同比较、比较推理、系列关系推理、抽象推理运算等方面的思维能力。\"]\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"智商测试\"}\n",
    "]\n",
    "\n",
    "params = {\n",
    "    \"provider\": \"coze\",\n",
    "    \"model\": \"coze\",\n",
    "    \"bot_id\": \"7355829428481769477\",\n",
    "    \"api_key\": \"pat_hodyfcRog0CfCAfEMtKAueI1I8yD2tDuDBSrvSRoXhKm1xLCw0HDiePtEVgRFHzt\",\n",
    "    \"stream\": False,\n",
    "    \"details\": True\n",
    "}\n",
    "\n",
    "response = unionchat(messages=messages, **params)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'context', 'ideal'],\n",
      "    num_rows: 1\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# create a dataset from the response for evaluation\n",
    "sampled = response.choices[0].message.content\n",
    "context = []\n",
    "for context_item in response.context:\n",
    "    context.append(context_item.content)\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    'question': [query],\n",
    "    'answer': [sampled], \n",
    "    'context': [context],\n",
    "    'ideal': [ideal]\n",
    "})\n",
    "print(dataset['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the evaluation parameters\n",
    "eval_params = {\n",
    "    \"provider\": \"zhipuai\",\n",
    "    \"model\": \"glm-4\",\n",
    "    \"api_key\": \"38dc046c622b6ec1b9bfa0413e6ca2ee.2Yn3uFr8j74pMOvK\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"stream\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with type\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'question'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# evaluate the dataset with the specified evaluator and print the results\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m faithfulness_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mFaithfulness\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(faithfulness_results)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(faithfulness_results\u001b[38;5;241m.\u001b[39mreasoning)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/zeval/evaluation.py:8\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset, evaluators, model_config)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m evaluator \u001b[38;5;129;01min\u001b[39;00m evaluators:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     score, reasoning, responses \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     result \u001b[38;5;241m=\u001b[39m Result(score, reasoning, responses)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/zeval/evaluators/faithfulness.py:144\u001b[0m, in \u001b[0;36mFaithfulness.score\u001b[0;34m(self, dataset, sample_kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     sample_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 144\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    145\u001b[0m answer \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    146\u001b[0m context \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'question'"
     ]
    }
   ],
   "source": [
    "# evaluate the dataset with the specified evaluator and print the results\n",
    "faithfulness_results = evaluate(dataset, [Faithfulness], eval_params)\n",
    "print(faithfulness_results)\n",
    "print(faithfulness_results.reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_client = EvalsOne(api_key='your_api_key_here')\n",
    "kwargs = {'messages': 'example message', 'completion': 'example completion'}\n",
    "response = eo_client.add_sample(**kwargs)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
